{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "64ab8e03-99ac-4a10-aa69-f89ce9bb2f9b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "secret=dbutils.secrets.get('databricklogin','databricklogin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d181e677-8ee4-4738-92cc-43cee7a77964",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "application_id =\"88dec17f-62f0-4cab-82b7-b9022c2cc21c\"\n",
    "service_credential=secret\n",
    "directory_id=\"037e0179-cd0e-4201-951c-167b7554d77a\"\n",
    "spark.conf.set(\"fs.azure.account.auth.type.datastoragenew12.dfs.core.windows.net\", \"OAuth\")\n",
    "spark.conf.set(\"fs.azure.account.oauth.provider.type.datastoragenew12.dfs.core.windows.net\", \"org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider\")\n",
    "spark.conf.set(\"fs.azure.account.oauth2.client.id.datastoragenew12.dfs.core.windows.net\", application_id)\n",
    "spark.conf.set(\"fs.azure.account.oauth2.client.secret.datastoragenew12.dfs.core.windows.net\", service_credential)\n",
    "spark.conf.set(\"fs.azure.account.oauth2.client.endpoint.datastoragenew12.dfs.core.windows.net\", f\"https://login.microsoftonline.com/{directory_id}/oauth2/token\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "08989ba8-83f1-42c4-beb8-ae3a5623d710",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "patients_df = spark.read.format(\"delta\").load(cleaned_patient_output_path)\n",
    "tests_df = spark.read.format(\"delta\").load(cleaned_test_output_path)\n",
    "\n",
    "# Join the cleaned patient and test data on PatientID\n",
    "joined_df = patients_df.join(tests_df, on=\"PatientID\", how=\"inner\")\n",
    "\n",
    "# Add a new column to indicate if a patient's test result is 'Positive' or 'Negative'\n",
    "joined_df = joined_df.withColumn(\"ResultStatus\", when(col(\"COVIDStatus\") == \"Positive\", lit(\"Positive\"))\n",
    "                                               .otherwise(lit(\"Negative\")))\n",
    "\n",
    "# Select and transform relevant columns for reporting\n",
    "etl_output_df = joined_df.select(\n",
    "    col(\"PatientID\"),\n",
    "    col(\"Age\"),\n",
    "    col(\"COVIDStatus\"),\n",
    "    col(\"TestID\"),\n",
    "    col(\"LabName\"),\n",
    "    col(\"ResultDate\"),\n",
    "    col(\"ResultStatus\")\n",
    ")\n",
    "\n",
    "# Show a preview of the transformed data\n",
    "etl_output_df.show()\n",
    "\n",
    "# Save the transformed data to Delta format in Azure Storage\n",
    "etl_output_path = \"abfss://gold@httpforstorage.dfs.core.windows.net/ETLResultData\"\n",
    "\n",
    "etl_output_df.write.format(\"delta\").mode(\"append\").save(etl_output_path)\n",
    "print(f\"ETL output data saved to {etl_output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "71f38e65-c15e-453d-8cf6-afc8ecc942eb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Cleaning",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}